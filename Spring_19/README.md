# Attention Models Fall 2019
Findings and Works in the lab for attention related models.

Keep here updated.

Tasks:
- ~~Read papers related to attention~~
- Implement attention (Task Reopened. See 4)
    - ~~Imitate tutorials~~
    - Look for the data they use
    - Adapt it to current work
    - Study and present __Memory Networks__
- ~~Back to the Future~~
    - ~~Implement LR and LSTM on IMDB~~
    - ~~Make an Analysis~~
    - ~~Implement MNB~~
- ~~Review Decision Trees~~ 
    - ~~Understand feature_importances_~~
- ~~Inquire coefficients with neutral values~~
    - ~~Use softmax~~
    - ~~Conclude best weights for decisions~~
    - ~~Try different ngrams~~
- Train a Feed-Forward Neural Net
    - ~~Use basic hidden layers and softmax~~
    - Reason: To find correlations between classes through hidden layers
    - Test it with the new testing data.
- Label a Randomly Sampled Data
    - Use it as the test set
    - Reason: train_test_split doesn't reflect the real world data.
