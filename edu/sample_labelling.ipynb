{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import scipy as sp\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.model_selection import train_test_split, ShuffleSplit\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn import linear_model, datasets\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "import csv\n",
    "import sys\n",
    "import random\n",
    "from sklearn.metrics import classification_report"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Labeling EDUs "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Sampler(object):\n",
    "    def __init__(self):\n",
    "        self.unlabeled = []\n",
    "        self.labeled = []\n",
    "        self.labels = []\n",
    "        with open(r\"UnlabeledEDUs.txt\") as infile: \n",
    "            for line in infile:  \n",
    "                self.unlabeled.append(line)\n",
    "        with open(r\"labeledEDUs.txt\") as infile: \n",
    "            for line in infile: \n",
    "                array = line.split(\" \")\n",
    "                if(\"<negative>\" in array): \n",
    "                    self.labels.append(0)\n",
    "                elif(\"<positive>\" in array): \n",
    "                    self.labels.append(0)\n",
    "                elif(\"<neutral>\" in array): \n",
    "                    self.labels.append(1)\n",
    "                else: \n",
    "                    continue\n",
    "                self.labeled.append(line)\n",
    "    def sample(self, k): \n",
    "        pass \n",
    "    def save(self): \n",
    "        with open(r\"UnlabeledEDUS.txt\", \"w\") as f: \n",
    "            for line in self.unlabeled: \n",
    "                f.write(line)  \n",
    "        with open(r\"LabeledEDUS.txt\", \"w\") as f: \n",
    "            for line in self.labeled: \n",
    "                f.write(line) \n",
    "                \n",
    "    def process_k_edus(self, k_indices): \n",
    "        for k in k_indices: \n",
    "            print(self.unlabeled[k]) \n",
    "            label = input(\"Please label this EDU: \")\n",
    "            if label==\"nega\":\n",
    "                label=\"negative\"\n",
    "            elif label==\"p\":\n",
    "                label=\"positive\"\n",
    "            elif label==\"neut\":\n",
    "                label=\"neutral\"\n",
    "            if(label==\"negative\"): \n",
    "                self.labels.append(0)\n",
    "            elif(\"positive\"==label): \n",
    "                self.labels.append(0)\n",
    "            elif(\"neutral\"== label): \n",
    "                self.labels.append(1)\n",
    "            else: \n",
    "                print(\"That label is not accepted\") \n",
    "                continue\n",
    "            i = self.unlabeled[k].index('\\n') \n",
    "            edu = self.unlabeled[k][:i] + ' <' + label + '> \\n'\n",
    "            self.labeled.append(edu)\n",
    "            \n",
    "        for i in sorted(k_indices, reverse=True): \n",
    "            del self.unlabeled[i] \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class RandomSampler(Sampler): \n",
    "    def sample(self,k): \n",
    "        k_indices = random.sample(range(0, len(self.unlabeled)),k)\n",
    "        return k_indices "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class UncertaintySampler(Sampler): \n",
    "    def sample(self,k): \n",
    "        X_labeled, y_labels, X_unlabeled= self.create()\n",
    "        logreg = LogisticRegression(C=1, solver = 'lbfgs', warm_start=True)\n",
    "        logreg.fit(X_labeled,y_labels) \n",
    "        probabilities = logreg.predict_proba(X_unlabeled)\n",
    "        p_neutral = probabilities[:,1]\n",
    "        p = []\n",
    "        for x in p_neutral: \n",
    "            p.append(abs(x-0.5)) \n",
    "        prob_neutral = np.argsort(p) \n",
    "        k_indices = [] \n",
    "        for i in range(k): \n",
    "            k_indices.append(prob_neutral[i])\n",
    "        return k_indices \n",
    "    def create(self): \n",
    "        X_train_corpus=[]\n",
    "        y_labels = []\n",
    "        for line in self.labeled:\n",
    "            array = line.split(\" \")\n",
    "            if(\"<negative>\" in array): \n",
    "                y_labels.append(-1)\n",
    "            elif(\"<positive>\" in array): \n",
    "                y_labels.append(1)\n",
    "            elif(\"<neutral>\" in array): \n",
    "                continue               \n",
    "            i = line.find('<')\n",
    "            line = line[:i]\n",
    "            X_train_corpus.append(line)\n",
    "    \n",
    "        X_test_corpus=self.unlabeled \n",
    "        token = r\"(?u)\\b[\\w\\'/]+\\b\"\n",
    "        tf_vectorizer = CountVectorizer(lowercase=True, max_df=1.0, min_df=1, binary=True, token_pattern=token)\n",
    "        tf_vectorizer.set_params(ngram_range=(1,1))\n",
    "        X_labeled = tf_vectorizer.fit_transform(X_train_corpus)\n",
    "        X_unlabeled = tf_vectorizer.transform(X_test_corpus)\n",
    "        return X_labeled, y_labels, X_unlabeled "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "this however does not live up to its excellent name .\n",
      "\n"
     ]
    }
   ],
   "source": [
    "rs = UncertaintySampler() \n",
    "cont = \"T\" \n",
    "while (cont==\"T\"): \n",
    "    k_indices = rs.sample(21)\n",
    "    rs.process_k_edus(k_indices)\n",
    "    rs.save()  \n",
    "    cont = input(\"continue? T/F \")\n",
    "     "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(rs.labeled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "labeled_data=[]\n",
    "data_labels= []\n",
    "neut = 0 \n",
    "neg =0 \n",
    "pos = 0 \n",
    "for line in rs.labeled:\n",
    "    array = line.split(\" \")\n",
    "    if(\"<negative>\" in array): \n",
    "        data_labels.append(-1)\n",
    "        neg = neg+1\n",
    "    elif(\"<positive>\" in array): \n",
    "        data_labels.append(1)\n",
    "        pos = pos+1\n",
    "    elif(\"<neutral>\" in array): \n",
    "        data_labels.append(0) \n",
    "        neut = neut+1\n",
    "    i = line.find('<')\n",
    "    line = line[:i]\n",
    "    labeled_data.append(line)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1048,
   "metadata": {},
   "outputs": [],
   "source": [
    "human_terms = [] \n",
    "with open(r\"/Users/dorsazeinali/Desktop/imdb-unigrams.txt\", 'r') as f:\n",
    "    for line in f: \n",
    "        i = line.find('<')\n",
    "        line = line[:i]\n",
    "        human_terms.append(line) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Labeling the human terms -1,1 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1049,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/10\n",
      "Please label this term P/NN\n",
      "2/10\n",
      "Please label this term P/NN\n",
      "3/10\n",
      "Please label this term P/NN\n",
      "4/10\n",
      "Please label this term P/NN\n",
      "5/10\n",
      "Please label this term P/NN\n",
      "6/10\n",
      "Please label this term P/NP\n",
      "7/10\n",
      "Please label this term P/NP\n",
      "8/10\n",
      "Please label this term P/NP\n",
      "9/10\n",
      "Please label this term P/NP\n",
      "10/10\n",
      "Please label this term P/NP\n",
      "amazing\n",
      "Please label this term P/NP\n",
      "annoying\n",
      "Please label this term P/NN\n",
      "avoid\n",
      "Please label this term P/NN\n",
      "awful\n",
      "Please label this term P/NN\n",
      "bad\n",
      "Please label this term P/NN\n",
      "badly\n",
      "Please label this term P/NN\n",
      "beautiful\n",
      "Please label this term P/NP\n",
      "beautifully\n",
      "Please label this term P/NP\n",
      "best\n",
      "Please label this term P/NP\n",
      "bland\n",
      "Please label this term P/NN\n",
      "boring\n",
      "Please label this term P/NN\n",
      "brilliant\n",
      "Please label this term P/NP\n",
      "cheap\n",
      "Please label this term P/NN\n",
      "disappointed\n",
      "Please label this term P/NN\n",
      "disappointing\n",
      "Please label this term P/NN\n",
      "disappointment\n",
      "Please label this term P/NN\n",
      "dreadful\n",
      "Please label this term P/NN\n",
      "dull\n",
      "Please label this term P/NN\n",
      "enjoyable\n",
      "Please label this term P/NP\n",
      "enjoyed\n",
      "Please label this term P/NP\n",
      "excellent\n",
      "Please label this term P/NP\n",
      "fails\n",
      "Please label this term P/NN\n",
      "fantastic\n",
      "Please label this term P/NP\n",
      "fascinating\n",
      "Please label this term P/NP\n",
      "favorite\n",
      "Please label this term P/NP\n",
      "forgettable\n",
      "Please label this term P/NN\n",
      "fun\n",
      "Please label this term P/NP\n",
      "funny\n",
      "Please label this term P/NP\n",
      "funniest\n",
      "Please label this term P/NP\n",
      "gem\n",
      "Please label this term P/NP\n",
      "great\n",
      "Please label this term P/NP\n",
      "horrible\n",
      "Please label this term P/NN\n",
      "incredible\n",
      "Please label this term P/NP\n",
      "insult\n",
      "Please label this term P/NN\n",
      "lacks\n",
      "Please label this term P/NN\n",
      "lame\n",
      "Please label this term P/NN\n",
      "laughable\n",
      "Please label this term P/NN\n",
      "lousy\n",
      "Please label this term P/NN\n",
      "loved\n",
      "Please label this term P/NP\n",
      "mediocre\n",
      "Please label this term P/NN\n",
      "mess\n",
      "Please label this term P/NN\n",
      "mst3k\n",
      "Please label this term P/NN\n",
      "noir\n",
      "Please label this term P/NN\n",
      "obnoxious\n",
      "Please label this term P/NN\n",
      "pathetic\n",
      "Please label this term P/NN\n",
      "perfect\n",
      "Please label this term P/NP\n",
      "perfectly\n",
      "Please label this term P/NP\n",
      "pointless\n",
      "Please label this term P/NN\n",
      "poor\n",
      "Please label this term P/NN\n",
      "poorly\n",
      "Please label this term P/NN\n",
      "predictable\n",
      "Please label this term P/NN\n",
      "rare\n",
      "Please label this term P/NP\n",
      "recommended\n",
      "Please label this term P/NP\n",
      "redeeming\n",
      "Please label this term P/NP\n",
      "refreshing\n",
      "Please label this term P/NP\n",
      "ridiculous\n",
      "Please label this term P/NN\n",
      "sadly\n",
      "Please label this term P/NN\n",
      "solid\n",
      "Please label this term P/NP\n",
      "stupid\n",
      "Please label this term P/NN\n",
      "subtle\n",
      "Please label this term P/NP\n",
      "superb\n",
      "Please label this term P/NP\n",
      "surprisingly\n",
      "Please label this term P/NP\n",
      "tedious\n",
      "Please label this term P/NN\n",
      "terrible\n",
      "Please label this term P/NN\n",
      "unfortunately\n",
      "Please label this term P/NN\n",
      "unfunny\n",
      "Please label this term P/NN\n",
      "waste\n",
      "Please label this term P/NN\n",
      "wasted\n",
      "Please label this term P/NN\n",
      "weak\n",
      "Please label this term P/NN\n",
      "wonderful\n",
      "Please label this term P/NP\n",
      "wonderfully\n",
      "Please label this term P/NP\n",
      "worse\n",
      "Please label this term P/NN\n",
      "wors\n",
      "Please label this term P/NN\n"
     ]
    }
   ],
   "source": [
    "human_terms_label = [] \n",
    "for term in human_terms: \n",
    "    print(term)\n",
    "    label = input(\"Please label this term P/N\")\n",
    "    human_terms_label.append(label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1050,
   "metadata": {},
   "outputs": [],
   "source": [
    "human_labels = [] \n",
    "for label in human_terms_label: \n",
    "    if(label ==\"N\"): \n",
    "        human_labels.append(-1)\n",
    "    if(label==\"P\"): \n",
    "        human_labels.append(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1061,
   "metadata": {},
   "outputs": [],
   "source": [
    "token = r\"(?u)\\b[\\w\\'/]+\\b\"\n",
    "tf_vectorizer = CountVectorizer(lowercase=True, max_df=1.0, min_df=1, binary=True, token_pattern=token, vocabulary = human_terms)\n",
    "tf_vectorizer.set_params(ngram_range=(1,1))\n",
    "X_train = tf_vectorizer.fit_transform(X_train_corpus)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1067,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'wors'"
      ]
     },
     "execution_count": 1067,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf_vectorizer.get_feature_names()[82]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1104,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2700"
      ]
     },
     "execution_count": 1104,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1174,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "#count = sum(1 for _ in re.finditer(r'\\b%s\\b' % re.escape(word), input_string))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
