{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import labeled_functions\n",
    "import numpy as np\n",
    "from sklearn.svm import SVC\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import precision_recall_curve, precision_score, precision_recall_fscore_support, confusion_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Labeled Data loaded.\n",
      "Data Vectorized\n"
     ]
    }
   ],
   "source": [
    "X_train_vector , y_train, X_test_vector , y_test = labeled_functions.split_and_vectorize()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((1318, 347), (660, 347))"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train_vector.shape, X_test_vector.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Finding 1:\n",
    "- One interesting finding is when I use 'linear' for the kernel; changing gamma didn't change both the accuracy and the confusion matrix. <-- BS. It changes them drastically. Fault in coding."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.7787878787878788, array([[264,  62],\n",
       "        [ 84, 250]]), array([0.80981595, 0.74850299]), array([0.75862069, 0.80128205]))"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Question: Why probability is False by default?\n",
    "svc = SVC(kernel='linear', C=1, gamma=0.2, probability=True) \n",
    "\n",
    "# Changing gamma, when kernel is 'linear' doesn't change the accuracy. Neither does it the confusion matrix.\n",
    "svc.fit(X_train_vector, y_train)\n",
    "accuracy = svc.score(X_test_vector, y_test)\n",
    "\n",
    "#Predict Output\n",
    "preds = svc.predict(X_test_vector)\n",
    "probs = svc.predict_proba(X_test_vector)\n",
    "\n",
    "conf_mat = confusion_matrix(preds, y_test)\n",
    "precision, recall, fscore, support = precision_recall_fscore_support(y_test, preds)\n",
    "accuracy, conf_mat, precision, recall"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([1, 0, 1, 0, 0, 1, 0, 1, 0, 1, 1, 0, 1, 1, 0, 1, 1, 0, 1, 0, 0, 1,\n",
       "        0, 1, 0, 0, 1, 1, 1, 0, 1, 0, 1, 1, 1, 0, 1, 1, 1, 1, 1, 0, 1, 1,\n",
       "        1, 1, 1, 1, 0, 0, 0, 0, 1, 0, 1, 0, 1, 0, 1, 0, 0, 0, 0, 1, 1, 1,\n",
       "        1, 1, 1, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 1, 0, 0, 0, 1, 1, 1, 0, 0,\n",
       "        1, 0, 1, 1, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 1, 1, 1, 0, 0, 0, 1, 1,\n",
       "        1, 1, 1, 1, 1, 1, 1, 0, 1, 0, 0, 0, 0, 1, 0, 1, 0, 1, 1, 1, 1, 1,\n",
       "        0, 1, 1, 1, 1, 1, 1, 0, 1, 1, 0, 1, 0, 0, 1, 1, 1, 1, 1, 0, 1, 1,\n",
       "        1, 0, 1, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 1, 1, 1, 0, 1, 0, 1, 0, 0,\n",
       "        0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 1, 1, 1, 0, 1, 0, 1, 0, 0, 0,\n",
       "        0, 1, 1, 1, 1, 0, 0, 0, 0, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 1, 0, 1,\n",
       "        1, 0, 0, 1, 0, 1, 0, 1, 0, 0, 1, 0, 1, 0, 0, 0, 1, 1, 0, 0, 1, 0,\n",
       "        1, 1, 0, 0, 0, 1, 0, 1, 0, 0, 0, 1, 0, 0, 1, 0, 0, 1, 1, 0, 0, 1,\n",
       "        0, 0, 1, 1, 1, 0, 1, 0, 1, 1, 1, 1, 0, 1, 1, 0, 0, 1, 0, 1, 0, 1,\n",
       "        0, 0, 1, 0, 1, 1, 1, 0, 0, 1, 1, 1, 0, 0, 1, 1, 1, 1, 1, 0, 0, 0,\n",
       "        1, 1, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 1, 1, 0, 0,\n",
       "        1, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 1, 1, 0, 1, 0, 1,\n",
       "        0, 0, 1, 0, 0, 0, 1, 1, 0, 1, 1, 0, 0, 0, 0, 1, 1, 0, 0, 1, 1, 1,\n",
       "        1, 1, 0, 1, 1, 1, 0, 1, 1, 0, 0, 1, 1, 1, 0, 0, 1, 0, 1, 0, 0, 1,\n",
       "        0, 1, 1, 0, 0, 0, 1, 0, 1, 0, 1, 0, 1, 1, 0, 0, 1, 0, 1, 0, 0, 0,\n",
       "        1, 0, 1, 1, 1, 0, 1, 1, 1, 0, 1, 1, 1, 1, 0, 0, 1, 0, 1, 1, 0, 1,\n",
       "        0, 1, 0, 0, 1, 0, 1, 1, 0, 1, 1, 1, 1, 0, 1, 0, 0, 1, 1, 1, 1, 1,\n",
       "        0, 0, 1, 0, 1, 0, 0, 1, 0, 1, 1, 1, 0, 0, 1, 0, 1, 0, 0, 1, 1, 0,\n",
       "        0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 1, 1, 0, 1, 1, 0, 0,\n",
       "        0, 0, 0, 1, 1, 0, 1, 1, 0, 0, 1, 0, 0, 0, 1, 1, 1, 1, 1, 1, 0, 0,\n",
       "        0, 0, 1, 0, 1, 1, 1, 0, 0, 1, 1, 0, 1, 1, 1, 1, 1, 1, 0, 0, 0, 1,\n",
       "        0, 1, 0, 1, 0, 1, 1, 0, 1, 1, 1, 1, 0, 0, 1, 1, 1, 1, 1, 1, 0, 0,\n",
       "        0, 1, 1, 0, 1, 0, 0, 1, 1, 1, 0, 1, 1, 1, 0, 0, 1, 1, 0, 1, 1, 1,\n",
       "        0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 1, 0, 1, 1, 0, 0, 1,\n",
       "        0, 1, 1, 0, 1, 0, 1, 1, 1, 0, 0, 0, 1, 1, 1, 1, 1, 0, 0, 1, 0, 0,\n",
       "        1, 1, 1, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 1, 1, 0, 1, 1, 0, 0, 0, 0]),\n",
       " array([[0.40649737, 0.59350263],\n",
       "        [0.72366879, 0.27633121],\n",
       "        [0.36358374, 0.63641626],\n",
       "        ...,\n",
       "        [0.70243085, 0.29756915],\n",
       "        [0.80201331, 0.19798669],\n",
       "        [0.71962734, 0.28037266]]))"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "preds, probs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Finding 2:\n",
    "- Another interesting finding is even if I use 'rbf' for the kernel; changing gamma didn't change the confusion matrix. Although, it changed the accuracy.\n",
    "- Well the statement above is wrong. I forgot to delete the comment for preds."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(0.01, 0.6333333333333333, array([[318, 212],\n",
       "         [ 30, 100]])), (0.1, 0.7666666666666667, array([[269,  75],\n",
       "         [ 79, 237]])), (0.2, 0.7636363636363637, array([[269,  77],\n",
       "         [ 79, 235]])), (0.5, 0.753030303030303, array([[306, 121],\n",
       "         [ 42, 191]])), (0.75, 0.6833333333333333, array([[320, 181],\n",
       "         [ 28, 131]])), (1, 0.6424242424242425, array([[327, 215],\n",
       "         [ 21,  97]])), (2, 0.5712121212121212, array([[333, 268],\n",
       "         [ 15,  44]])), (5, 0.553030303030303, array([[344, 291],\n",
       "         [  4,  21]])), (10, 0.553030303030303, array([[344, 291],\n",
       "         [  4,  21]]))]"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results = []\n",
    "for gamma in [0.01,0.1,0.2,0.5,0.75,1,2,5,10]:\n",
    "    svc = SVC(kernel=\"rbf\", C=1, gamma=gamma, probability=True) \n",
    "    svc.fit(X_train_vector, y_train)\n",
    "    accuracy = svc.score(X_test_vector, y_test)\n",
    "    preds = svc.predict(X_test_vector)\n",
    "    probs = svc.predict_proba(X_test_vector)\n",
    "    conf_mat = confusion_matrix(preds, y_test)\n",
    "    results.append((gamma, accuracy, conf_mat))\n",
    "results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(0.01, 0.5272727272727272, array([[348, 312],\n",
       "         [  0,   0]])), (0.1, 0.5272727272727272, array([[348, 312],\n",
       "         [  0,   0]])), (0.2, 0.5333333333333333, array([[348, 308],\n",
       "         [  0,   4]])), (0.5, 0.5681818181818182, array([[341, 278],\n",
       "         [  7,  34]])), (0.75, 0.5954545454545455, array([[337, 256],\n",
       "         [ 11,  56]])), (1, 0.6424242424242425, array([[327, 215],\n",
       "         [ 21,  97]])), (2, 0.6454545454545455, array([[313, 199],\n",
       "         [ 35, 113]])), (5, 0.6409090909090909, array([[310, 199],\n",
       "         [ 38, 113]])), (10, 0.6409090909090909, array([[310, 199],\n",
       "         [ 38, 113]]))]"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results = []\n",
    "for alpha in [0.01,0.1,0.2,0.5,0.75,1,2,5,10]:\n",
    "    svc = SVC(kernel=\"rbf\", C=alpha, gamma=1, probability=True) \n",
    "    svc.fit(X_train_vector, y_train)\n",
    "    accuracy = svc.score(X_test_vector, y_test)\n",
    "    preds = svc.predict(X_test_vector)\n",
    "    probs = svc.predict_proba(X_test_vector)\n",
    "    conf_mat = confusion_matrix(preds, y_test)\n",
    "    results.append((alpha, accuracy, conf_mat))\n",
    "results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.7954545454545454, 0.9400606980273141, array([[269,  56],\n",
       "        [ 79, 256]]), array([0.82769231, 0.7641791 ]), array([0.77298851, 0.82051282]))"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# The best accuracy is reached when C=2, gamma=0.1\n",
    "svc = SVC(kernel=\"rbf\", C=2, gamma=0.1, probability=True) \n",
    "svc.fit(X_train_vector, y_train)\n",
    "accuracy = svc.score(X_test_vector, y_test)\n",
    "accuracy_train = svc.score(X_train_vector, y_train)\n",
    "preds = svc.predict(X_test_vector)\n",
    "probs = svc.predict_proba(X_test_vector)\n",
    "conf_mat = confusion_matrix(preds, y_test)\n",
    "\n",
    "precision, recall, fscore, support = precision_recall_fscore_support(y_test, preds)\n",
    "(accuracy, accuracy_train, conf_mat ,precision, recall)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(0.01, 0.5272727272727272, array([[348, 312],\n",
       "         [  0,   0]])), (0.1, 0.706060606060606, array([[265, 111],\n",
       "         [ 83, 201]])), (0.2, 0.6378787878787879, array([[231, 122],\n",
       "         [117, 190]])), (0.5, 0.6151515151515151, array([[222, 128],\n",
       "         [126, 184]])), (0.75, 0.6090909090909091, array([[218, 128],\n",
       "         [130, 184]])), (1, 0.6106060606060606, array([[218, 127],\n",
       "         [130, 185]])), (2, 0.5909090909090909, array([[207, 129],\n",
       "         [141, 183]])), (5, 0.5893939393939394, array([[206, 129],\n",
       "         [142, 183]])), (10, 0.5863636363636363, array([[203, 128],\n",
       "         [145, 184]]))]"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results = []\n",
    "for alpha in [0.01,0.1,0.2,0.5,0.75,1,2,5,10]:\n",
    "    svc = SVC(kernel=\"sigmoid\", C=alpha, gamma=1, probability=True) \n",
    "    svc.fit(X_train_vector, y_train)\n",
    "    accuracy = svc.score(X_test_vector, y_test)\n",
    "    preds = svc.predict(X_test_vector)\n",
    "    probs = svc.predict_proba(X_test_vector)\n",
    "    conf_mat = confusion_matrix(preds, y_test)\n",
    "    results.append((alpha, accuracy, conf_mat))\n",
    "results"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
